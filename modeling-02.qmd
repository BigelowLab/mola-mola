---
title: "Modeling each month"
cache: true
---

Here we modify our first modeling workflow to produce a model for each month. In the [previous workflow](modeling-01.qmd) we produced one model covering observations covering all times; we then applied the model to the various months. 

## Load data

Here we load the observation and background data points. We add a column identifying the month of the year. 

```{r}
source("setup.R")
obs = sf::read_sf(file.path("data", "obs", "obs-covariates.gpkg")) |>
  sf::st_set_geometry("geometry") |>
  dplyr::mutate(month = factor(format(month_id, "%b"), levels = month.abb), 
                .before = geometry)
bkg = sf::read_sf(file.path("data", "bkg", "bkg-covariates.gpkg")) |>
  sf::st_set_geometry("geometry") |>
  dplyr::mutate(month = factor(format(month_id, "%b"), levels = month.abb), 
                .before = geometry)
```

## Do we model every month?

Let's do a quick check by counting each by month. Note that we drop the spatial info so that we can make simply tallies.

```{r}
counts = sf::st_drop_geometry(obs) |> 
  dplyr::count(month, name = "n_obs") |>
  dplyr::left_join(sf::st_drop_geometry(bkg) |> dplyr::count(month, name = "n_bkg"), 
                   by = 'month') |>
  print(n = 12)
```

So the colder months have fewer observations than the warmer months.  We already knew that, but it will be interesting to see how that manifests itself in the models.

### Build the monthly models

```{r}

# A function for making one month's model
#
# @param tbl a data frame of one month's observations
# @param key a data frame that holds the current iteration's month name
# @param bkg a complete data frame of background data (which we filter for the given month)
# @param path the path where the model is saved
# @return a model, which is also saved in "data/model/v2/v2.<monthname>"
model_month = function(tbl, key, bkg = NULL, path = "."){
  
  bkg = bkg |>
    dplyr::filter(month == key$month) |>
    sf::st_drop_geometry() |>
    dplyr::select(dplyr::all_of(c("sst", "u_wind", "v_wind"))) |>
    na.omit()
  
  obs = tbl |>
    sf::st_drop_geometry() |>
    dplyr::select(dplyr::all_of(c("sst", "u_wind", "v_wind"))) |>
    na.omit()
  
  # these are the predictor variables row bound
  x = dplyr::bind_rows(obs, bkg)
  
  # and the flag indicating presence/background
  flag = c(rep(1, nrow(obs)), rep(0, nrow(bkg)))
  
  model_path = file.path(path, paste0("v2.", key$month, ".rds"))

  model = maxnet::maxnet(flag, x) |>
    maxnetic::write_maxnet(model_path)
                         
  model
}

path = file.path("data", "model", "v2")
ok = dir.create(path, recursive = TRUE, showWarnings = FALSE)
models = obs |>
  dplyr::group_by(month) |>
  dplyr::group_map(model_month, bkg = bkg, path = path) |>
  rlang::set_names(levels(obs$month))
```

## Predict with rasters

First we load the raster databases as these are lightweight to pass into a function that iterates through the months.

### Load the raster databases (`sst` and `u_wind` and `v_wind`)

We also make sure they are in date order and add a "month" variable to each.

```{r}
sst_path = "data/oisst"
sst_db = oisster::read_database(sst_path) |>
  dplyr::arrange(date) |>
  dplyr::mutate(month = format(date, "%b"))
  

wind_path = "data/nbs"
wind_db = nbs::read_database(wind_path) |>
  dplyr::arrange(date)|>
  dplyr::mutate(month = format(date, "%b"))

u_wind_db = wind_db |>
  dplyr::filter(param == "u_wind")

v_wind_db = wind_db |>
  dplyr::filter(param == "v_wind")
```

### Iterate through the months making predictions
Now we can build an iterator function that will make a prediction for each month.  Let's narrow our predictions to just those for a particular year, 2019, and read the rasters in all at once.

```{r}
dates = as.Date(c("2019-01-01", "2019-12-31"))
x = read_predictors(
  sst_db = dplyr::filter(sst_db, dplyr::between(date, dates[1], dates[2])),
  u_wind_db = dplyr::filter(u_wind_db, dplyr::between(date, dates[1], dates[2])),
  v_wind_db = dplyr::filter(v_wind_db, dplyr::between(date, dates[1], dates[2]))
)
```

Now we can iterate through the months.

```{r}
date_sequence = seq(from = dates[1], to = dates[2], by = "month")
pred_rasters = lapply(names(models),
  function(mon){
    ix = which(month.abb %in% mon)
    predict(models[[mon]], dplyr::slice(x, time, ix, drop), type = "cloglog")
  }) 
pred_rasters = do.call(c, append(pred_rasters, list(along = list(time = date_sequence))))
```

Let's plot them.

```{r}
coast = rnaturalearth::ne_coastline(scale = 'large', returnclass = 'sf') |>
  sf::st_geometry() |>
  sf::st_crop(pred_rasters)

plot_coast = function() {
  plot(coast, col = 'green', add = TRUE)
}
plot(pred_rasters |> st_to_180(), hook = plot_coast)
```

Let's see what we can discern from the predict abilities. We can extract the predicted values at the observed locations.



```{r}
pred_obs = stars::st_extract(pred_rasters, 
                             dplyr::filter(obs, dplyr::between(date, dates[1], dates[2])),
                             time_column = "month_id") |>
  sf::st_drop_geometry() 
pred_bkg = stars::st_extract(pred_rasters, 
                             dplyr::filter(bkg, dplyr::between(date, dates[1], dates[2])),
                             time_column = "month_id") |>
  sf::st_drop_geometry() 

preds = dplyr::bind_rows(pred_obs, pred_bkg) |>
  dplyr::mutate(label = c(rep(1, nrow(pred_obs)), rep(0, nrow(pred_bkg))), .before = 1) |>
  dplyr::mutate(month = factor(format(time, "%b"), levels = month.abb)) |>
  dplyr::group_by(month)


aucs = dplyr::group_map(preds,
                        function(x, y) {
                          dplyr::tibble(month = y$month, auc = maxnetic::AUC(x))
                        }) |>
  dplyr::bind_rows() |>
  dplyr::right_join(counts, by = "month") |>
  print(n=12)
```

OK, that's unexpected.  The months with the lower counts of observations have relatively higher AUCs.  Huh?  Let's look at that graphically.

```{r}
aucs_long = tidyr::pivot_longer(aucs, dplyr::all_of(c("n_obs", "n_bkg")),
                           names_to = "type", values_to = "count") |>
  dplyr::mutate(type = dplyr::recode(type, n_obs = "obs", n_bkg = "bkg"))

ggplot2::ggplot(data = aucs_long, aes(x = count, y = auc, color = type)) +
  ggplot2::geom_point() + 
  ggplot2::geom_smooth(method='lm', formula= y~x)
```
Surprised?  Could this be overfitting resulting from sampling background in time weighted to the months when we have observations?  Hmmmm.
